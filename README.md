# Meeting Transcription & MoM Generator

A Windows desktop application for real-time meeting transcription and Minutes of Meeting (MoM) generation. Captures both microphone and system audio, transcribes speech to text, and exports formatted transcripts.

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/python-3.10+-green)
![Platform](https://img.shields.io/badge/platform-Windows%2010%2F11-lightgrey)
![License](https://img.shields.io/badge/license-MIT-orange)

## âœ¨ Features

### Audio Capture
- **Microphone Recording** - Capture your voice during meetings
- **System Audio Loopback** - Record audio from Teams, Zoom, or any application
- **Dual Channel Support** - Record both mic and system audio simultaneously
- **WASAPI Backend** - High-quality Windows audio capture

### Transcription Engines (3 Options)

#### ğŸŒ Chrome Web Speech API (Recommended for most users)
- âœ… **Free** - No API costs
- âœ… **Real-time** - See transcription as you speak
- âœ… **Good accuracy** - Google-powered
- âœ… **Easy setup** - No model downloads
- âŒ Requires internet connection
- âŒ Privacy concern (audio sent to Google)

#### ğŸ”’ Whisper (Best for privacy)
- âœ… **Offline** - Works without internet
- âœ… **High quality** - OpenAI's SOTA model
- âœ… **Private** - All processing local
- âœ… **Free** - Open source
- âŒ Requires GPU/CPU power
- âŒ Large model downloads (1-3 GB)
- âŒ Slower than real-time

#### â˜ï¸ Azure Speech Service (Enterprise)
- âœ… **Highly accurate** - Enterprise-grade
- âœ… **Fast** - Cloud processing
- âœ… **Reliable** - Microsoft infrastructure
- âŒ Requires Azure subscription
- âŒ API costs apply
- âŒ Requires internet

### Export & Formatting
- ğŸ“„ **Markdown Export** - Formatted with timestamps and sections
- ğŸ“ **Plain Text Export** - Simple timestamped transcript
- â±ï¸ **Timestamps** - Track when each segment was spoken
- ğŸ’¾ **Auto-save Recordings** - All audio saved to `recordings/` folder

## ğŸš€ Quick Start

### Prerequisites
- **Windows 10/11** (64-bit)
- **Python 3.10+** ([Download here](https://www.python.org/downloads/))
- **Chrome or Edge browser** (for Chrome Speech API option)

### Installation

1. **Clone or download this repository**
   ```powershell
   cd c:\Src2\speech2text
   ```

2. **Run the setup script**
   ```powershell
   .\setup.ps1
   ```
   
   This will:
   - Create a virtual environment
   - Install all dependencies
   - Create configuration files

3. **Activate the virtual environment**
   ```powershell
   .\venv\Scripts\Activate.ps1
   ```

4. **(Optional) Configure Azure Speech Service**
   
   If you want to use Azure transcription:
   - Edit `.env` file
   - Add your Azure credentials:
     ```
     AZURE_SPEECH_KEY=your_key_here
     AZURE_SPEECH_REGION=your_region_here
     TRANSCRIPTION_MODE=azure
     ```

5. **Run the application**
   ```powershell
   python run.py
   ```

## ğŸ“– Usage Guide

### Recording a Meeting

#### Option 1: Chrome Web Speech (Real-time)

1. **Select "Chrome Web Speech API" from the engine dropdown**
2. **Click "Open Chrome Speech Recognition"**
   - Browser window opens
   - Grant microphone permissions
3. **Click "Start Listening" in the browser**
4. **Speak naturally** - transcript appears in real-time in both browser and app
5. **Save transcript** when done

**Best for:** Quick meetings, real-time transcription, minimal setup

#### Option 2: Record then Transcribe (Whisper/Azure)

1. **Select audio sources:**
   - âœ“ Microphone - Check to record your voice
   - âœ“ System Audio - Check to record Teams/Zoom audio
2. **Select transcription engine** (Whisper or Azure)
3. **Click "Start Recording"**
4. **Conduct your meeting**
5. **Click "Stop Recording"**
6. **Click "Transcribe"** - wait for processing
7. **Save transcript** as TXT or Markdown

**Best for:** Offline transcription, high accuracy, longer meetings

### Exporting Transcripts

**Save as Markdown (.md)**
```markdown
# Meeting Transcript

**Date:** 2025-12-03 14:30:00
**Duration:** 245.50 seconds
**Segments:** 12

---

### Segment 1 [0:00:00]

Hello everyone, welcome to today's meeting...

### Segment 2 [0:00:15]

Let's discuss the project timeline...
```

**Save as Text (.txt)**
```
Meeting Transcript - 2025-12-03 14:30:00
======================================================================

[0:00:00] Hello everyone, welcome to today's meeting...
[0:00:15] Let's discuss the project timeline...
```

## ğŸ› ï¸ Configuration

### Audio Settings (`config.py` or `.env`)

```python
SAMPLE_RATE=16000      # Audio sample rate (Hz)
CHANNELS=1             # Mono (1) or Stereo (2)
CHUNK_SIZE=1024        # Audio buffer size
```

### Transcription Settings

```python
TRANSCRIPTION_MODE=chrome   # Default engine: chrome, whisper, or azure
WHISPER_MODEL=base          # Whisper model size: tiny, base, small, medium, large
```

**Whisper Model Sizes:**
| Model  | Size   | Speed   | Accuracy  | Use Case          |
| ------ | ------ | ------- | --------- | ----------------- |
| tiny   | 75 MB  | Fast    | Good      | Quick transcripts |
| base   | 142 MB | Fast    | Better    | **Recommended**   |
| small  | 466 MB | Medium  | Great     | High accuracy     |
| medium | 1.5 GB | Slow    | Excellent | Best quality      |
| large  | 2.9 GB | Slowest | Best      | Maximum accuracy  |

## ğŸ”§ Troubleshooting

### Common Issues

#### "No loopback device found" / Can't record system audio

**Solution 1: Enable Stereo Mix (Built-in Windows)**
1. Right-click speaker icon in taskbar â†’ **Sounds**
2. Go to **Recording** tab
3. Right-click empty area â†’ **Show Disabled Devices**
4. Right-click **Stereo Mix** â†’ **Enable**
5. Restart the app and refresh devices

**Solution 2: Use Virtual Audio Cable**
1. Install [VB-Audio Virtual Cable](https://vb-audio.com/Cable/) (free)
2. Set as default playback device
3. Restart app

#### Chrome Web Speech not working

**Symptoms:** Browser says "Speech recognition not supported"

**Solutions:**
- âœ“ Use Chrome or Edge browser (not Firefox/Safari)
- âœ“ Check microphone permissions in browser
- âœ“ Ensure website has HTTPS or is localhost
- âœ“ Try restarting the browser

#### Whisper transcription is very slow

**Solutions:**
- Use smaller model: `WHISPER_MODEL=tiny` or `base`
- Install CUDA for GPU acceleration:
  ```powershell
  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
  ```
- Reduce audio quality: `SAMPLE_RATE=8000`

#### "Module not found" errors

**Solution:**
```powershell
# Ensure virtual environment is activated
.\venv\Scripts\Activate.ps1

# Reinstall dependencies
pip install -r requirements.txt
```

#### Transcription accuracy is poor

**Solutions:**
- Use better microphone
- Reduce background noise
- Speak clearly and at moderate pace
- Use larger Whisper model: `WHISPER_MODEL=medium`
- Switch to Azure Speech Service for best accuracy

### Debug Audio Devices

Run the audio capture test:
```powershell
python audio_capture.py
```

This will list all available devices and test recording.

## ğŸ“ Project Structure

```
speech2text/
â”œâ”€â”€ main.py                  # Main GUI application
â”œâ”€â”€ audio_capture.py         # Audio recording module
â”œâ”€â”€ transcription.py         # Transcription engines
â”œâ”€â”€ config.py               # Configuration
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ setup.ps1              # Setup script
â”œâ”€â”€ .env                   # User configuration (not in git)
â”œâ”€â”€ .env.example          # Configuration template
â”‚
â”œâ”€â”€ recordings/           # Saved audio files (auto-created)
â”œâ”€â”€ transcripts/         # Exported transcripts (auto-created)
â”œâ”€â”€ models/             # Whisper model cache (auto-created)
â””â”€â”€ venv/              # Virtual environment (auto-created)
```

## ğŸ”Œ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PyQt6 GUI     â”‚
â”‚   (main.py)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Audio   â”‚  â”‚
â”‚ Capture  â”‚  â”‚
â”‚ (WASAPI) â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚    â”‚
         â”‚  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  â”‚ Transcription   â”‚
         â”‚  â”‚   Manager       â”‚
         â”‚  â””â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚    â”‚   â”‚   â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â–¼â”€â”€â”€â–¼â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  Chrome  Whisper  Azure â”‚
    â”‚   (Web)  (Local) (Cloud)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Use Cases

### Business Meetings
- Record team discussions
- Generate meeting minutes automatically
- Track action items and decisions
- Share transcripts with absent team members

### Interviews
- Transcribe job interviews
- Document user research sessions
- Create searchable interview archives

### Lectures & Training
- Capture webinars and presentations
- Create study notes from online courses
- Transcribe training sessions

### Personal
- Journal voice notes
- Transcribe podcasts
- Create content from brainstorming sessions

## ğŸ”’ Privacy & Security

### Local Transcription (Whisper)
- âœ… All processing happens on your computer
- âœ… No data sent to external servers
- âœ… Complete privacy

### Cloud Transcription (Chrome/Azure)
- âš ï¸ Audio sent to external servers
- âš ï¸ Subject to provider's privacy policy
- âœ… Encrypted in transit (HTTPS/WSS)

**Recommendation:** Use Whisper for sensitive/confidential meetings.

## ğŸš§ Known Limitations

1. **System audio capture requires Stereo Mix or virtual audio cable**
   - Not all systems have this enabled by default
   
2. **Chrome Web Speech requires internet**
   - Not suitable for offline meetings
   
3. **Whisper is slow on CPU-only systems**
   - Consider GPU acceleration or smaller models
   
4. **No speaker diarization yet**
   - Cannot automatically identify different speakers
   - Planned for future version

5. **Windows-only**
   - WASAPI is Windows-specific
   - macOS/Linux support planned

## ğŸ—ºï¸ Roadmap

### Phase 2 (Future Enhancements)
- [ ] Speaker diarization (identify who's speaking)
- [ ] Real-time transcription for Whisper
- [ ] Multi-language support
- [ ] Keyword extraction and summarization
- [ ] Integration with calendar apps
- [ ] Audio playback with synchronized transcript
- [ ] Export to PDF, DOCX
- [ ] Custom vocabulary/terminology

## ğŸ“„ License

MIT License - Feel free to use, modify, and distribute.

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

## ğŸ’¬ Support

**Issues?** Check the Troubleshooting section above or open a GitHub issue.

**Questions?** Start a discussion in GitHub Discussions.

## ğŸ™ Credits

Built with:
- [OpenAI Whisper](https://github.com/openai/whisper) - Local transcription
- [PyQt6](https://www.riverbankcomputing.com/software/pyqt/) - Desktop GUI
- [sounddevice](https://python-sounddevice.readthedocs.io/) - Audio capture
- [Azure Speech SDK](https://docs.microsoft.com/azure/cognitive-services/speech-service/) - Cloud transcription
- [Chrome Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) - Browser-based transcription

---

**Made with â¤ï¸ for better meeting productivity**
